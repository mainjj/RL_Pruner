{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deep RL 기반 Neural Network Pruning 구현\n",
    "Neural Network를 pruning 하기 위한 Deep Reinforcement Learning 기반 알고리즘 구현을 목표로 한다.\n",
    "\n",
    "1. Baseline_Net 학습\n",
    "    - pruning을 할 Network이며 CIFAR10 dataset을 활용하여 ResNet50을 학습한다.\n",
    "2. RL기반 Pruning 진행\n",
    "3. Pruning된 model 재학습\n",
    "4. model test (Mac 및 param 개수 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-13 10:01:30.628825: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-06-13 10:01:30.859820: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-06-13 10:01:31.630764: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "from RL_tool import Env, PolicyNetwork\n",
    "from datetime import datetime\n",
    "import torch.optim as optim\n",
    "import torch\n",
    "\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "\n",
    "from torch.utils.tensorboard import SummaryWriter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtime = datetime.now().strftime(\"%m%d_%H%M\")\n",
    "\n",
    "writer = SummaryWriter(f'runs/result_{dtime}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Baseline_Net 학습\n",
    "- pruning을 할 Network이며 CIFAR10 dataset을 활용하여 ResNet50을 학습한다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from resnet_train import train\n",
    "\n",
    "train(epochs=200, batch_size=128, lr=0.001, model_path='', name=f\"ResNet50_{dtime}\", is_pruned=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. RL기반 Pruning 진행\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "DNN_path = f\"./checkpoints/ResNet50_{dtime}.pth\"\n",
    "env = Env(DNN_path)\n",
    "policy_network = PolicyNetwork()\n",
    "\n",
    "learning_rate=0.01\n",
    "optimizer = optim.Adam(policy_network.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Action_list = np.arange(0, 1.00, 0.01)\n",
    "\n",
    "gamma=0.75\n",
    "episodes=100\n",
    "\n",
    "is_best = {\"sparsity\": 50, \"acc\":60}\n",
    "total_rewards = []\n",
    "total_sparsity = []\n",
    "total_resnet_acc = []\n",
    "for episode in range(episodes):\n",
    "    log_probs = []\n",
    "    rewards = []\n",
    "    state = env.reset()\n",
    "    \n",
    "    for i in tqdm(range(len(env.order_to_prune)), desc=f\"{episode+1}/{episodes}\"):\n",
    "        state = torch.FloatTensor(state).unsqueeze(0)\n",
    "        action_probs = policy_network(state)\n",
    "        action = torch.multinomial(action_probs, num_samples=1).item()\n",
    "\n",
    "        log_prob = torch.log(action_probs.squeeze(0)[action])\n",
    "        log_probs.append(log_prob)\n",
    "        next_state, reward = env.step(i, Action_list[action])\n",
    "        rewards.append(reward)\n",
    "        \n",
    "        state = next_state\n",
    "\n",
    "    discounted_rewards = []\n",
    "    cumulative_reward = 0\n",
    "    for reward in reversed(rewards):\n",
    "        cumulative_reward = reward + gamma * cumulative_reward\n",
    "        discounted_rewards.insert(0, cumulative_reward)\n",
    "    \n",
    "    discounted_rewards = torch.FloatTensor(discounted_rewards)\n",
    "    discounted_rewards = (discounted_rewards - discounted_rewards.mean()) / (discounted_rewards.std() + 1e-9)\n",
    "    baseline = discounted_rewards.mean()\n",
    "\n",
    "    policy_loss = []\n",
    "    for log_prob, reward in zip(log_probs, discounted_rewards):\n",
    "        policy_loss.append(-log_prob * (reward - baseline))\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "    policy_loss = torch.stack(policy_loss).sum()\n",
    "\n",
    "    policy_loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    \n",
    "    total_rewards.append(np.mean(rewards))\n",
    "    total_sparsity.append(state[0]*100)\n",
    "    total_resnet_acc.append(state[1]*100)\n",
    "\n",
    "    writer.add_scalar('Total Reward', np.mean(rewards), episode)\n",
    "    writer.add_scalar('sparsity', round(state[0]*100,2), episode)\n",
    "    writer.add_scalar('Resnet_acc', round(state[1]*100,2), episode)\n",
    "    print(f\"Episode {episode+1}, return: {np.mean(rewards)}, sparsity: {round(state[0]*100,2)}, Resnet_acc: {round(state[1]*100,2)}/{round(env.resnet.orig_test_acc*100,2)}\")\n",
    "    \n",
    "    if is_best['sparsity'] < round(state[0]*100,2):\n",
    "        is_best['sparsity']  =  round(state[0]*100,2)\n",
    "        env.resnet.save(f\"{dtime}_episode{episode}_s{round(state[0]*100,2)}_a{round(state[1]*100,2)}\")\n",
    "    if is_best['acc'] < round(state[1]*100,2):\n",
    "        is_best['acc'] = round(state[1]*100,2)\n",
    "        env.resnet.save(f\"{dtime}_episode{episode}_s{round(state[0]*100,2)}_a{round(state[1]*100,2)}\")\n",
    "\n",
    "writer.close()\n",
    "\n",
    "torch.save(policy_network.state_dict(), f\"./checkpoints/PolicyNet_{dtime}.pt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Pruning된 model 재학습\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from resnet_train import train\n",
    "\n",
    "model_path = \"$PATH$\" # 재학습할 model.pth 위치\n",
    "name = \"$name$\" # 재학습된 model 저장이름\n",
    "train(epochs=200, batch_size=128, lr=0.001, model_path=model_path, name=name, is_pruned=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. model test\n",
    "- Mac 및 param 개수 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# \n",
    "import torch\n",
    "from torchvision.models import resnet50, ResNet50_Weights\n",
    "import torch.nn as nn\n",
    "\n",
    "\n",
    "model_path = \"$ Pruned Model Path $\"\n",
    "\n",
    "# model setting\n",
    "pruned_net = resnet50(weights=ResNet50_Weights.DEFAULT)\n",
    "pruned_net.fc = nn.Linear(pruned_net.fc.in_features, 10)\n",
    "pruned_net.load_state_dict(torch.load(model_path))\n",
    "pruned_net.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "##### Pruned Network #####\n",
      "\n",
      "Computational complexity:       1.43 GMac\n",
      "Number of parameters:           7,665,530\n"
     ]
    }
   ],
   "source": [
    "from ptflops import get_model_complexity_info\n",
    "\n",
    "with torch.cuda.device(0):\n",
    "  macs, _ = get_model_complexity_info(pruned_net, (3, 224, 224), as_strings=True, backend='pytorch',\n",
    "                                           print_per_layer_stat=False, verbose=False)\n",
    "  params = 0\n",
    "  for i in pruned_net.parameters():\n",
    "      params += torch.count_nonzero(i).cpu()\n",
    "\n",
    "  print('##### Pruned Network #####\\n')\n",
    "  print('{:<30}  {:<8}'.format('Computational complexity: ', macs))\n",
    "  print('{:<30}  {:<8,}'.format('Number of parameters: ', params))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "##### Baseline Network #####\n",
      "\n",
      "Computational complexity:       4.13 GMac\n",
      "Number of parameters:           23,528,522\n"
     ]
    }
   ],
   "source": [
    "baseline_net = resnet50(weights=ResNet50_Weights.DEFAULT)\n",
    "baseline_net.fc = nn.Linear(baseline_net.fc.in_features, 10)\n",
    "baseline_net.cuda()\n",
    "\n",
    "with torch.cuda.device(0):\n",
    "  macs, _ = get_model_complexity_info(baseline_net, (3, 224, 224), as_strings=True, backend='pytorch',\n",
    "                                           print_per_layer_stat=False, verbose=False)\n",
    "  params = 0\n",
    "  for i in baseline_net.parameters():\n",
    "      params += torch.count_nonzero(i).cpu()\n",
    "\n",
    "  print('##### Baseline Network #####\\n')\n",
    "  print('{:<30}  {:<8}'.format('Computational complexity: ', macs))\n",
    "  print('{:<30}  {:<8,}'.format('Number of parameters: ', params))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.1.-1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
